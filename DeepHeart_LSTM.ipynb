{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7036,"status":"ok","timestamp":1693128628459,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"S_Rczqsq5uBx"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, random_split, DataLoader\n","import torch.nn as nn\n","from collections import Counter\n","import os\n","import zipfile\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import confusion_matrix,f1_score, accuracy_score\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.model_selection import KFold"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26886,"status":"ok","timestamp":1693128655336,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"yuSTxe5ni2Sr","outputId":"c62ecaa0-61b4-4b4d-f762-e3c75c28e9bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":100542,"status":"ok","timestamp":1693128755875,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"lu3AUSeCkKJM"},"outputs":[],"source":["import zipfile\n","zip_path = \"/content/drive/MyDrive/DeepHeart/outputs_6leads.zip\"\n","output_dir = \"/content\"\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(output_dir)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1693128755876,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"yn-q9JM0iXhC"},"outputs":[],"source":["class ECG_Data(Dataset):\n","\n","    def __init__(self, df, window_size):\n","        self.df = df\n","        self.window_size = window_size\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        age = torch.tensor([int(self.df.iloc[index, 1])])\n","        sex = torch.tensor([0]) if self.df.iloc[index, 2] == 'Male' else torch.tensor([1])\n","        label = torch.tensor([int(self.df.iloc[index, 3])])\n","\n","        file_name = \"/content/outputs_6leads/\" + self.df.iloc[index, 0] + \".csv\"\n","        data = pd.read_csv(file_name)\n","        lead_data = data.iloc[:, 1:7].values.astype(float)\n","        windowed_lead_data = []\n","        for i in range(0, len(lead_data) - window_size + 1, window_size):              #windowing the lead data\n","              windowed_lead_data.append(lead_data[i:i+window_size])\n","        windowed_lead_data = torch.Tensor(windowed_lead_data)\n","        windowed_lead_data = torch.sum(windowed_lead_data, dim = 1)\n","\n","        return windowed_lead_data, label, age, sex"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1693128755876,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"czOGXexpi0pa"},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/DeepHeart/patients_outputs_6leads.csv\")\n","df = df.dropna()\n","\n","# df_ones = df[df['Label'] == 1].copy()\n","# df_zeros = df[df['Label'] == 0].sample(n=10000, random_state=42).copy()\n","# df_final = pd.concat([df_ones, df_zeros])\n","# df_final.reset_index(drop=True, inplace=True)\n","df_final = df\n","\n","num_folds = 5\n","kfold = KFold(n_splits=num_folds, shuffle=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1693128755876,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"XJAfzdvPqQkF"},"outputs":[],"source":["fold_datasets = []\n","window_size = 100\n","for train_indices, test_indices in kfold.split(df_final):\n","    train_data = df_final.iloc[train_indices]\n","    test_data = df_final.iloc[test_indices]\n","\n","    train_dataset = ECG_Data(train_data, window_size)\n","    test_dataset = ECG_Data(test_data, window_size)\n","\n","    fold_datasets.append((train_dataset, test_dataset))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693128755876,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"XsnP_qAbqEEY","outputId":"17ef61fe-e5ce-40a7-a4e6-59100196f296"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}],"source":["batch_size = 64\n","\n","data_loaders = []\n","for train_dataset, test_dataset in fold_datasets:\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    data_loaders.append((train_loader, test_loader))\n","\n","device=torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"executionInfo":{"elapsed":1803,"status":"ok","timestamp":1693128757675,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"hX_BJpSJml_F","outputId":"475e1f09-4ce2-4075-8141-0dd877c875a5"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-e84a2e1281b1>:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  windowed_lead_data = torch.Tensor(windowed_lead_data)\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([64, 50, 6])\n","torch.Size([64, 1])\n","torch.Size([64, 1])\n","torch.Size([64, 1])\n"]},{"output_type":"execute_result","data":{"text/plain":["       File_Name    Age    Sex\n","Label                         \n","0          36972  36972  36972\n","1           8123   8123   8123"],"text/html":["\n","  <div id=\"df-530bbf08-7a0c-40c7-ba08-e79fb7152f3a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File_Name</th>\n","      <th>Age</th>\n","      <th>Sex</th>\n","    </tr>\n","    <tr>\n","      <th>Label</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>36972</td>\n","      <td>36972</td>\n","      <td>36972</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8123</td>\n","      <td>8123</td>\n","      <td>8123</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-530bbf08-7a0c-40c7-ba08-e79fb7152f3a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-530bbf08-7a0c-40c7-ba08-e79fb7152f3a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-530bbf08-7a0c-40c7-ba08-e79fb7152f3a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":8}],"source":["for data, label, age, sex in train_loader:\n","  print(data.size())\n","  print(age.size())\n","  print(label.size())\n","  print(sex.size())\n","  break\n","\n","df_final.groupby('Label').count()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1693128757675,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"IhYxfdct53BS"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, device):\n","        super(Model,self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.device = device\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        '''self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)'''\n","        #self.self_attention = nn.MultiheadAttention(input_size, num_heads = <place the number of heads here>)\n","        self.fc = nn.Sequential(nn.Linear(hidden_size * 3, 500),\n","                                nn.Linear(500, 2))\n","\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def positional_encoding(self, var, size):\n","        inv_freq = 1.0 / (\n","            10000\n","            ** (torch.arange(0, size, 2, device=self.device).float() / size)\n","        )\n","        pos_enc_a = torch.sin(var.repeat(1, size // 2) * inv_freq)\n","        pos_enc_b = torch.cos(var.repeat(1, size // 2) * inv_freq)\n","        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n","        return pos_enc\n","\n","\n","    def forward(self, lead_data, age, sex):\n","        batch_size = lead_data.size(0)\n","        seq_length = lead_data.size(1)\n","        # h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n","        # c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n","\n","        h0 = torch.zeros(self.num_layers*2, batch_size, self.hidden_size).to(self.device)\n","        c0 = torch.zeros(self.num_layers*2, batch_size, self.hidden_size).to(self.device)\n","        # print(h0.size(), lead_data.size())\n","\n","        lstm_out, _ = self.lstm(lead_data, (h0, c0))\n","        # print(lstm_out.size())\n","\n","        #lead_data = lead_data.permute(1,0,2)\n","        #attention_out,_ = self.self_attention(lead_data,lead_data,lead_data)\n","        #attention_out = attention_out.permute(1,0,2)\n","        #last_output = attention_out[:,-1,:]\n","\n","        last_output = lstm_out[:, -1, :]\n","\n","        age = self.positional_encoding(age, 64)\n","        sex = self.positional_encoding(sex, 64)\n","\n","        combined = torch.cat((last_output, age, sex), dim=1)\n","\n","        output = self.fc(combined)   #applying final layers\n","        output = self.sigmoid(output)\n","\n","        return output"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693128757676,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"Q94HmpYXL6cf","outputId":"fdb36e82-52ba-4c9b-f4f4-f61e1804c155"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nimport xgboost as xgb\\nfrom xgboost import XGBClassifier\\n\\n#data from torch tensor to numpy arrays, ds is the class instance of ECGDataset\\n\\nlead_data,label,age,sex = ds[0]\\nlead_data = lead_data.numpy()\\nlabel = label.numpy()\\nage = age.numpy()\\nsex = sex.numpy()\\n\\nlead_data_flattened = lead_data.reshape(lead_data.shape[0], -1)\\nfeatures = np.hstack((lead_data_flattened, age.reshape(-1,1), sex.reshape(-1,1)))\\n#another approach is that we do not flatten the lead data as shown below\\n#features = np.concatenate((lead_data, np.repeat(age, lead_data.shape[0], axis=0)[:, np.newaxis], np.repeat(sex, lead_data.shape[0], axis=0)[:, np.newaxis]), axis=2)\\n\\nX_train,X_test,y_train,y_test = train_test_split(features, label, test_size=0.2, random_state=42)\\n\\n#this is the RF implementation\\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\\nrf.fit(X_train, y_train)\\ny_pred = rf.predict(X_test)\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(\"Accuracy:\", accuracy)\\n\\n\\n#this is xgb implementation\\nparams = {\\n    \\'booster\\': \\'gbtree\\',\\n    \\'n_estimator\\': \\'100\\',\\n    \\'eta\\': 0.1,\\n    \\'max_depth\\': 5,\\n    \\'lambda\\': 1.0,\\n    \\'objective\\': \\'binary:logistic\\',\\n    \\'eval_metric\\': \\'auc\\'\\n}\\n\\nxgb_cl = xgb.XGBClassifier(**params)\\ndtrain = xgb.DMatrix(X_train, label=y_train)\\ndtest = xgb.DMatrix(X_test, label=y_test)\\nxgb_cl.fit(X_train, y_train)\\ny_pred = xgb_cl.predict(X_test)\\naccuracy = accuracy_score(y_test, y_pred)\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["'''\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","\n","#data from torch tensor to numpy arrays, ds is the class instance of ECGDataset\n","\n","lead_data,label,age,sex = ds[0]\n","lead_data = lead_data.numpy()\n","label = label.numpy()\n","age = age.numpy()\n","sex = sex.numpy()\n","\n","lead_data_flattened = lead_data.reshape(lead_data.shape[0], -1)\n","features = np.hstack((lead_data_flattened, age.reshape(-1,1), sex.reshape(-1,1)))\n","#another approach is that we do not flatten the lead data as shown below\n","#features = np.concatenate((lead_data, np.repeat(age, lead_data.shape[0], axis=0)[:, np.newaxis], np.repeat(sex, lead_data.shape[0], axis=0)[:, np.newaxis]), axis=2)\n","\n","X_train,X_test,y_train,y_test = train_test_split(features, label, test_size=0.2, random_state=42)\n","\n","#this is the RF implementation\n","rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf.fit(X_train, y_train)\n","y_pred = rf.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","\n","#this is xgb implementation\n","params = {\n","    'booster': 'gbtree',\n","    'n_estimator': '100',\n","    'eta': 0.1,\n","    'max_depth': 5,\n","    'lambda': 1.0,\n","    'objective': 'binary:logistic',\n","    'eval_metric': 'auc'\n","}\n","\n","xgb_cl = xgb.XGBClassifier(**params)\n","dtrain = xgb.DMatrix(X_train, label=y_train)\n","dtest = xgb.DMatrix(X_test, label=y_test)\n","xgb_cl.fit(X_train, y_train)\n","y_pred = xgb_cl.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","'''"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3576,"status":"ok","timestamp":1693128761246,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"1nrPBknxCko0","outputId":"5043b70c-42a5-48be-a374-5aa550d34dad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({0: 36972, 1: 8123}) tensor([1.2197, 4.5000], device='cuda:0') (array([0, 1]), array([36972,  8123]))\n"]}],"source":["labels_lst = np.array(df_final['Label'])\n","\n","class_freq = Counter(labels_lst)\n","num_classes = len(class_freq)\n","\n","# Calculate class weights based on inverse frequency\n","total_samples = len(labels_lst)\n","class_weights = [total_samples / (class_freq[i] + 1e-8) for i in range(num_classes)]\n","class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n","class_weights[1] = 4.5\n","\n","# Define the weighted loss function\n","criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n","# criterion = torch.nn.CrossEntropyLoss()\n","print(class_freq, class_weights, np.unique(labels_lst, return_counts = True))"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693136258622,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"},"user_tz":-330},"id":"rSdEY0a084fU"},"outputs":[],"source":["def train(train_loader, test_loader, model, optimizer, loss_criteria = nn.BCELoss(), batchsize = batch_size, epochs = 50):\n","  val_losses = []\n","  train_losses = []\n","\n","  for epoch in range(epochs):\n","      train_loss = 0.0\n","      val_loss = 0.0\n","      min_loss = 1000.0\n","\n","\n","      model.train()\n","      for i, (lead_data, labels, age, sex) in enumerate(tqdm(train_loader)):\n","\n","          lead_data = lead_data.to(device)\n","          age = age.to(device)\n","          sex = sex.to(device)\n","\n","          labels = F.one_hot(labels, num_classes=2)\n","          labels = labels.type(torch.FloatTensor)\n","          labels = labels.squeeze()\n","          labels = labels.to(device)\n","\n","          optimizer.zero_grad()\n","          outputs = model(lead_data, age, sex)\n","          loss = loss_criteria(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          train_loss += loss.item() * lead_data.size(0)\n","          if loss.item() < min_loss:\n","            min_loss = loss.item()\n","          if (i + 1) % 50 == 0:\n","            print(\"EPOCH : {}/{}, MIN_LOSS : {}, LOSS : {}\".format(epoch + 1, epochs, min_loss, loss.item()))\n","\n","      train_loss /= len(train_loader.dataset)\n","      train_losses.append(train_loss)\n","\n","      # Validation\n","      model.eval()\n","      predictions = []\n","      actual = []\n","      with torch.no_grad():\n","          for lead_data, labels, age, sex in tqdm(test_loader):\n","              lead_data = lead_data.to(device)\n","              age = age.to(device)\n","              sex = sex.to(device)\n","\n","              outputs = model(lead_data, age, sex)\n","              _, predicted = torch.max(outputs, 1)\n","              for i in range(labels.size(0)):\n","                  label = labels[i]\n","                  pred = predicted[i]\n","                  predictions.append(pred.item())\n","                  actual.append(label.item())\n","          cm = confusion_matrix(actual, predictions)\n","          print(classification_report(actual, predictions))\n","          disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n","          disp.plot()\n","          plt.show()\n","          torch.save(model.state_dict(), '/content/drive/MyDrive/DeepHeart/deepheart_bilstm.pt')"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"PVQ_yeR5sKJ8","outputId":"01d8c74f-dc4c-418a-c7c1-bc1a88161146","executionInfo":{"status":"error","timestamp":1693138813044,"user_tz":-330,"elapsed":16787,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["  2%|▏         | 11/564 [00:16<13:37,  1.48s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-ea70f125dc3c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_criteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=====================================================STEP : {}/{} COMPLETE=====================================================\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-f1b2e483f67e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader, model, optimizer, loss_criteria, batchsize, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlead_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mlead_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlead_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-e84a2e1281b1>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlead_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;31m#windowing the lead data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0mwindowed_lead_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlead_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mwindowed_lead_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindowed_lead_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mwindowed_lead_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindowed_lead_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for fold_idx, (train_loader, test_loader) in enumerate(data_loaders):\n","  input_size = 6\n","  num_layers = 2\n","  # hidden_size = 256\n","  hidden_size = 128\n","  model = Model(input_size,hidden_size,num_layers, device).to(device)\n","  try:\n","    model.load_state_dict(torch.load('/content/drive/MyDrive/DeepHeart/deepheart_bilstm.pt'))\n","  except:\n","    print(\"no saved model found\")\n","  optimizer=torch.optim.AdamW(model.parameters(),lr=0.0003)\n","\n","  train(train_loader, test_loader, model, optimizer, loss_criteria = criterion, epochs = 15)\n","  print(\"=====================================================STEP : {}/{} COMPLETE=====================================================\".format(fold_idx + 1, num_folds))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hesiwtEf_qEX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
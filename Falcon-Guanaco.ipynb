{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BiQiw31DT7-cDp1-0ySXvvhzqomTdI-o","timestamp":1689448655595}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"158e9a05f20847088cf76a2e536e4194":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf338ed3fef2437dace0bb083c037d64","IPY_MODEL_bff14eb3b0e24f9798e7ca2037e53090","IPY_MODEL_ba1f1bffa35744cfa4c839f3d532a9dc"],"layout":"IPY_MODEL_5e5da02763ec4d69b6786507a6a5347d"}},"cf338ed3fef2437dace0bb083c037d64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a1284efdc394971b9499dfb22ced09e","placeholder":"​","style":"IPY_MODEL_d815f55fbda940348d958f93a950dc16","value":"Downloading (…)lve/main/config.json: 100%"}},"bff14eb3b0e24f9798e7ca2037e53090":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eda5eb6b7f2f4bd0a9d7e17e9e5b8d1a","max":1102,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab99a6ec1eb942ae8d024b40ff49b2ce","value":1102}},"ba1f1bffa35744cfa4c839f3d532a9dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3918ae74d9184584acf28f04fa590852","placeholder":"​","style":"IPY_MODEL_9e42526ddd7b465c8dcfeed3ee7af29b","value":" 1.10k/1.10k [00:00&lt;00:00, 36.1kB/s]"}},"5e5da02763ec4d69b6786507a6a5347d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a1284efdc394971b9499dfb22ced09e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d815f55fbda940348d958f93a950dc16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eda5eb6b7f2f4bd0a9d7e17e9e5b8d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab99a6ec1eb942ae8d024b40ff49b2ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3918ae74d9184584acf28f04fa590852":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e42526ddd7b465c8dcfeed3ee7af29b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"328d68006f094ed0adde5859ac310af4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13cda57efec14c739ad3c2a180ab452e","IPY_MODEL_b959f5e08fcf46d5a28b1ce285332974","IPY_MODEL_e897de82f57e4372b61595df8ee3c5fe"],"layout":"IPY_MODEL_393559e13d4040fe84f803cc1eab9144"}},"13cda57efec14c739ad3c2a180ab452e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3608f2794d747789c843dea4bb8ca6c","placeholder":"​","style":"IPY_MODEL_c5398eda27fe4d52b4b55957b1510209","value":"Downloading (…)/configuration_RW.py: 100%"}},"b959f5e08fcf46d5a28b1ce285332974":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50ab51dc88914fc18b9f8fae909fd3dc","max":2607,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93823473280d407282476eb445ed6c5f","value":2607}},"e897de82f57e4372b61595df8ee3c5fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6cd3bfc9f044ed8a9774dce9e1a9395","placeholder":"​","style":"IPY_MODEL_0fa44970ee6a4df2a516154e148fe449","value":" 2.61k/2.61k [00:00&lt;00:00, 75.2kB/s]"}},"393559e13d4040fe84f803cc1eab9144":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3608f2794d747789c843dea4bb8ca6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5398eda27fe4d52b4b55957b1510209":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50ab51dc88914fc18b9f8fae909fd3dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93823473280d407282476eb445ed6c5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6cd3bfc9f044ed8a9774dce9e1a9395":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fa44970ee6a4df2a516154e148fe449":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc640d70c93e4868a7040d9c9f815394":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd930da48a5d4dec820db93a525a1723","IPY_MODEL_f8a26bd9b8cd474b8a429e778866e347","IPY_MODEL_5cb9ecd7653d4e45b71dac018f186ad6"],"layout":"IPY_MODEL_740831e41fe6484c9284ee45c01d60e8"}},"cd930da48a5d4dec820db93a525a1723":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92799548ae8647788ecac4d96b0d6bf8","placeholder":"​","style":"IPY_MODEL_616b9cdca4be468ca0f833df60aae551","value":"Downloading (…)main/modelling_RW.py: 100%"}},"f8a26bd9b8cd474b8a429e778866e347":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23d4e383b0824472a67a0081e1f480fd","max":47560,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cb9c1bac43c42009f802dc438de90ad","value":47560}},"5cb9ecd7653d4e45b71dac018f186ad6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7ec18d9cb664cd49ef064b225d5abb7","placeholder":"​","style":"IPY_MODEL_9e1289bbbe24436a8518919a4a32de0c","value":" 47.6k/47.6k [00:00&lt;00:00, 2.41MB/s]"}},"740831e41fe6484c9284ee45c01d60e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92799548ae8647788ecac4d96b0d6bf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"616b9cdca4be468ca0f833df60aae551":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23d4e383b0824472a67a0081e1f480fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cb9c1bac43c42009f802dc438de90ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7ec18d9cb664cd49ef064b225d5abb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e1289bbbe24436a8518919a4a32de0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## Finetune Falcon-7b on a Google colab\n","\n","Welcome to this Google Colab notebook that shows how to fine-tune the recent Falcon-7b model on a single Google colab and turn it into a chatbot\n","\n","We will leverage PEFT library from Hugging Face ecosystem, as well as QLoRA for more memory efficient finetuning"],"metadata":{"id":"C2EgqEPDQ8v6"}},{"cell_type":"markdown","source":["## Setup\n","\n","Run the cells below to setup and install the required libraries. For our experiment we will need `accelerate`, `peft`, `transformers`, `datasets` and TRL to leverage the recent [`SFTTrainer`](https://huggingface.co/docs/trl/main/en/sft_trainer). We will use `bitsandbytes` to [quantize the base model into 4bit](https://huggingface.co/blog/4bit-transformers-bitsandbytes). We will also install `einops` as it is a requirement to load Falcon models."],"metadata":{"id":"i-tTvEF1RT3y"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNnkgBq7Q3EU","executionInfo":{"status":"ok","timestamp":1689533516614,"user_tz":-330,"elapsed":44317,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"}},"outputId":"e819133b-7e3e-4c29-f9c8-830076d51a34"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.7/214.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n","!pip install -q datasets bitsandbytes einops wandb"]},{"cell_type":"markdown","source":["## Dataset\n","\n","For our experiment, we will use the Guanaco dataset, which is a clean subset of the OpenAssistant dataset adapted to train general purpose chatbots.\n","\n","The dataset can be found [here](https://huggingface.co/datasets/timdettmers/openassistant-guanaco)"],"metadata":{"id":"Rnqmq7amRrU8"}},{"cell_type":"code","source":["import json\n","\n","parsed_data = []\n","\n","with open('train.json', 'r') as file:\n","    for line in file:\n","        try:\n","            json_data = json.loads(line)\n","            parsed_data.append(json_data)\n","        except:\n","            error_line = line.strip()\n","            print(\"Error line:\", error_line)\n","\n","new_dict = {\n","    \"version\": \"0.1.0\",\n","    \"data\": parsed_data\n","}\n","\n","converted_json = json.dumps(new_dict, indent=4)\n","\n","with open('train_mod.json', 'w') as file:\n","    file.write(converted_json)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRtpzeMRDb__","executionInfo":{"status":"ok","timestamp":1689534522001,"user_tz":-330,"elapsed":9124,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"}},"outputId":"516c5938-9a55-43bc-fb0f-b2cb18a12687"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error line: {\"question\":\"A female aged 30 presents with episodic throbbing headache for past 4 years. It usually involves one half of the face and is associated with nausea and vomiting. There is no\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","# dataset_name = \"timdettmers/openassistant-guanaco\"\n","# dataset = load_dataset(\"imdb\", split=\"train\")\n","dataset = load_dataset('json', data_files='train_mod.json', field = 'data', split = \"train\")\n","print(len(dataset))\n","dataset[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0X3kHnskSWU4","executionInfo":{"status":"ok","timestamp":1689534568026,"user_tz":-330,"elapsed":478,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"}},"outputId":"4b74fe2e-aa6d-45fe-9eb3-45810656c24b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-91e61c99e5f872d9/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"]},{"output_type":"stream","name":"stdout","text":["110693\n"]},{"output_type":"execute_result","data":{"text/plain":["{'opc': 'Duodenal Switch',\n"," 'choice_type': 'multi',\n"," 'exp': \"Ans. is 'd' i.e., Roux en Y Duodenal Bypass Bariatric surgical procedures include:a. Vertical banded gastroplastyb. Adjustable gastric bandingc. Roux-en Y gastric bypass (Not - Roux-en Y Duodenal Bypass)d. Biliopancreatic diversione. Duodenal switcho The surgical treatment of morbid obesity is known as bariatric surgery.o Morbid obesity is defined as body mass index of 35 kg/m2 or more with obesity related comorbidity, or BMI of 40 kg/m2 or greater without comorbidity.o Bariatric operations produce weight loss as a result of 2 factors. One is restriction of oralintake. The other is malabsorbtion of ingested food.o Gastric restrictive procedures include Vertical banded gastroplasty & Adjustable gastric bandingo Malabsorbtive procedures include Biliopancreatic diversion, and Duodenal switcho Roux-en Y gastric bypass has features of both restriction and malabsorptionBariatric Operations: Mechanism of ActionRestrictiveVertical banded gastroplastyLaparoscopic adjustable gastric bandingLargely Restrictive/Mildly MalabsorptiveRoux-en-Y gastric bypassLargely Malabsorptive/Mildly RestrictiveBiliopancreatic diversionDuodenal switch\",\n"," 'opa': 'Adjustable gastric banding',\n"," 'question': 'All of the following are surgical options for morbid obesity except -',\n"," 'subject_name': 'Surgery',\n"," 'id': '5c38bea6-787a-44a9-b2df-88f4218ab914',\n"," 'opb': 'Biliopancreatic diversion',\n"," 'topic_name': 'Surgical Treatment Obesity',\n"," 'cop': 4,\n"," 'opd': 'Roux en Y Duodenal By pass'}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["opts_dict = {1 : 'Option A', 2 : 'Option B', 3 : 'Option C', 4 : 'Option D'}\n","\n","def formatting_prompts_func(example):\n","    output_texts = []\n","    for i in range(len(example['question'])):\n","        text = f\"### Question: {example['question'][i]}\\n Option A: {example['opa'][i]}\\n Option B: {example['opb'][i]}\\n Option C: {example['opc'][i]}\\n Option D: {example['opd'][i]} ### Answer: {opts_dict[int(example['cop'][i])]}\"\n","        output_texts.append(text)\n","    return output_texts"],"metadata":{"id":"wGdE_kmiHFIg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["j = 50\n","for i in dataset[j]:\n","  print(i, dataset[j][i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tFeJQX2y_pL1","executionInfo":{"status":"ok","timestamp":1689535136856,"user_tz":-330,"elapsed":717,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"}},"outputId":"6f9162ad-6a05-4943-897b-5558663c4e07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["opc Find out cause or disease specific\n","choice_type multi\n","exp (A1I of the above) (54- Park 20th)Specific death rates - may be (a) cause or disease specific e.g. TB, cancer, accidents (b) Related to specific groups e.g. age specific, sex specific, age and sex specific etc.* Rates can also be made specific for many others variables such as income, religion, race, housing etc.* Specific death rates can help us to identify particular groups or groups \"at risk\" for preventive action. They permit comparisons between different causes within the same populations* Specific death rates are obtained mainly in countries in which a satisfactory civil registration system operates and in which a high proportion of death is certified medically.\n","opa Specific for age and sex\n","question True statement regarding specific death rates\n","subject_name Social & Preventive Medicine\n","id 8a72ed74-b546-481b-bf0c-0c812ce2f3df\n","opb Identify particular group or groups \"at risk\" for preventive action\n","topic_name Concept of Health and Disease\n","cop 4\n","opd All of the above\n"]}]},{"cell_type":"markdown","source":["## Loading the model"],"metadata":{"id":"rjOMoSbGSxx9"}},{"cell_type":"markdown","source":["In this section we will load the [Falcon 7B model](https://huggingface.co/tiiuae/falcon-7b), quantize it in 4bit and attach LoRA adapters on it. Let's get started!"],"metadata":{"id":"AjB0WAqFSzlD"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n","\n","model_name = \"ybelkada/falcon-7b-sharded-bf16\"\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    trust_remote_code=True\n",")\n","model.config.use_cache = False"],"metadata":{"id":"ZwXZbQ2dSwzI","colab":{"base_uri":"https://localhost:8080/","height":669,"referenced_widgets":["158e9a05f20847088cf76a2e536e4194","cf338ed3fef2437dace0bb083c037d64","bff14eb3b0e24f9798e7ca2037e53090","ba1f1bffa35744cfa4c839f3d532a9dc","5e5da02763ec4d69b6786507a6a5347d","9a1284efdc394971b9499dfb22ced09e","d815f55fbda940348d958f93a950dc16","eda5eb6b7f2f4bd0a9d7e17e9e5b8d1a","ab99a6ec1eb942ae8d024b40ff49b2ce","3918ae74d9184584acf28f04fa590852","9e42526ddd7b465c8dcfeed3ee7af29b","328d68006f094ed0adde5859ac310af4","13cda57efec14c739ad3c2a180ab452e","b959f5e08fcf46d5a28b1ce285332974","e897de82f57e4372b61595df8ee3c5fe","393559e13d4040fe84f803cc1eab9144","a3608f2794d747789c843dea4bb8ca6c","c5398eda27fe4d52b4b55957b1510209","50ab51dc88914fc18b9f8fae909fd3dc","93823473280d407282476eb445ed6c5f","a6cd3bfc9f044ed8a9774dce9e1a9395","0fa44970ee6a4df2a516154e148fe449","fc640d70c93e4868a7040d9c9f815394","cd930da48a5d4dec820db93a525a1723","f8a26bd9b8cd474b8a429e778866e347","5cb9ecd7653d4e45b71dac018f186ad6","740831e41fe6484c9284ee45c01d60e8","92799548ae8647788ecac4d96b0d6bf8","616b9cdca4be468ca0f833df60aae551","23d4e383b0824472a67a0081e1f480fd","3cb9c1bac43c42009f802dc438de90ad","e7ec18d9cb664cd49ef064b225d5abb7","9e1289bbbe24436a8518919a4a32de0c"]},"executionInfo":{"status":"error","timestamp":1689535163253,"user_tz":-330,"elapsed":21888,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"}},"outputId":"a7c28281-3c69-4181-a9a1-344d8f81d3b3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"158e9a05f20847088cf76a2e536e4194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/configuration_RW.py:   0%|          | 0.00/2.61k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"328d68006f094ed0adde5859ac310af4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n","- configuration_RW.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)main/modelling_RW.py:   0%|          | 0.00/47.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc640d70c93e4868a7040d9c9f815394"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n","- modelling_RW.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n","  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"]},{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-7666cf652fda>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             )\n\u001b[1;32m    478\u001b[0m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2275\u001b[0m                     \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2276\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2277\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No GPU found. A GPU is needed for quantization.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2278\u001b[0m                 logger.info(\n\u001b[1;32m   2279\u001b[0m                     \u001b[0;34m\"The device_map was not initialized.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: No GPU found. A GPU is needed for quantization."]}]},{"cell_type":"markdown","source":["Let's also load the tokenizer below"],"metadata":{"id":"xNqIYtQcUBSm"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token"],"metadata":{"id":"XDS2yYmlUAD6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Below we will load the configuration file in order to create the LoRA model. According to QLoRA paper, it is important to consider all linear layers in the transformer block for maximum performance. Therefore we will add `dense`, `dense_h_to_4_h` and `dense_4h_to_h` layers in the target modules in addition to the mixed query key value layer."],"metadata":{"id":"NuAx3zBeUL1q"}},{"cell_type":"code","source":["from peft import LoraConfig\n","\n","lora_alpha = 16\n","lora_dropout = 0.1\n","lora_r = 64\n","\n","peft_config = LoraConfig(\n","    lora_alpha=lora_alpha,\n","    lora_dropout=lora_dropout,\n","    r=lora_r,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=[\n","        \"query_key_value\",\n","        \"dense\",\n","        \"dense_h_to_4h\",\n","        \"dense_4h_to_h\",\n","    ]\n",")"],"metadata":{"id":"dQdvjTYTT1vQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loading the trainer"],"metadata":{"id":"dzsYHLwIZoLm"}},{"cell_type":"markdown","source":["Here we will use the [`SFTTrainer` from TRL library](https://huggingface.co/docs/trl/main/en/sft_trainer) that gives a wrapper around transformers `Trainer` to easily fine-tune models on instruction based datasets using PEFT adapters. Let's first load the training arguments below."],"metadata":{"id":"aTBJVE4PaJwK"}},{"cell_type":"code","source":["from transformers import TrainingArguments\n","\n","output_dir = \"./results\"\n","per_device_train_batch_size = 4\n","gradient_accumulation_steps = 4\n","optim = \"paged_adamw_32bit\"\n","save_steps = 10\n","logging_steps = 10\n","learning_rate = 2e-4\n","max_grad_norm = 0.3\n","max_steps = 500\n","warmup_ratio = 0.03\n","lr_scheduler_type = \"constant\"\n","\n","training_arguments = TrainingArguments(\n","    output_dir=output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    optim=optim,\n","    save_steps=save_steps,\n","    logging_steps=logging_steps,\n","    learning_rate=learning_rate,\n","    fp16=True,\n","    max_grad_norm=max_grad_norm,\n","    max_steps=max_steps,\n","    warmup_ratio=warmup_ratio,\n","    group_by_length=True,\n","    lr_scheduler_type=lr_scheduler_type,\n",")"],"metadata":{"id":"OCFTvGW6aspE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then finally pass everthing to the trainer"],"metadata":{"id":"I3t6b2TkcJwy"}},{"cell_type":"code","source":["from trl import SFTTrainer\n","\n","max_seq_length = 512\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset,\n","    peft_config=peft_config,\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    formatting_func=formatting_prompts_func,\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n",")"],"metadata":{"id":"TNeOBgZeTl2H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We will also pre-process the model by upcasting the layer norms in float 32 for more stable training"],"metadata":{"id":"GWplqqDjb3sS"}},{"cell_type":"code","source":["for name, module in trainer.model.named_modules():\n","    if \"norm\" in name:\n","        module = module.to(torch.float32)"],"metadata":{"id":"7OyIvEx7b1GT","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"error","timestamp":1689535164240,"user_tz":-330,"elapsed":3,"user":{"displayName":"SHIVAM MITTAL 2K21/A12/71","userId":"02425131177498648534"}},"outputId":"da461eef-b2bf-4da4-cfcc-deb6d37166d2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-56cd0c51464b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"norm\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"]}]},{"cell_type":"markdown","source":["## Train the model"],"metadata":{"id":"1JApkSrCcL3O"}},{"cell_type":"markdown","source":["Now let's train the model! Simply call `trainer.train()`"],"metadata":{"id":"JjvisllacNZM"}},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"_kbS7nRxcMt7","outputId":"72b4220a-91de-4b69-a572-82e2943d9ada"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20230715_192830-kthwpnqx</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/shivammittal/huggingface/runs/kthwpnqx' target=\"_blank\">silver-dew-1</a></strong> to <a href='https://wandb.ai/shivammittal/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/shivammittal/huggingface' target=\"_blank\">https://wandb.ai/shivammittal/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/shivammittal/huggingface/runs/kthwpnqx' target=\"_blank\">https://wandb.ai/shivammittal/huggingface/runs/kthwpnqx</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  4/500 00:58 < 4:01:10, 0.03 it/s, Epoch 0.00/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"markdown","source":["During training, the model should converge nicely as follows:\n","\n","![image](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/loss-falcon-7b.png)\n","\n","The `SFTTrainer` also takes care of properly saving only the adapters during training instead of saving the entire model."],"metadata":{"id":"H5c0ppfasK29"}}]}